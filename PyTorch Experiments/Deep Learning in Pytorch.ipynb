{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  __future__ import print_function\n",
    "import torch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.9393e+00,  4.5562e-41, -1.9393e+00],\n",
      "        [ 4.5562e-41,  1.6255e-43,  1.5554e-43],\n",
      "        [ 1.5975e-43,  1.3873e-43,  1.4574e-43],\n",
      "        [ 6.4460e-44,  1.4153e-43,  1.5274e-43],\n",
      "        [ 1.5695e-43,  1.6255e-43,  1.6956e-43]])\n",
      "tensor([[ 0.3226,  0.7654,  0.9202],\n",
      "        [ 0.9469,  0.8257,  0.2831],\n",
      "        [ 0.5871,  0.4555,  0.7124],\n",
      "        [ 0.2747,  0.6945,  0.7272],\n",
      "        [ 0.1420,  0.0884,  0.1037]])\n",
      "tensor([[-0.9242,  0.6442, -0.7695],\n",
      "        [ 0.7384,  0.6782,  0.2758],\n",
      "        [ 0.5278,  0.4264,  0.6122],\n",
      "        [ 0.2680,  0.6009,  0.6213],\n",
      "        [ 0.1411,  0.0882,  0.1033]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.empty(5,3)\n",
    "y = torch.rand(5,3)\n",
    "print(x)\n",
    "print(y)\n",
    "print(torch.tanh(x+y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.9393e+00,  4.5562e-41, -1.9393e+00,  4.5562e-41,  1.6255e-43,\n",
       "         1.5554e-43,  1.5975e-43,  1.3873e-43,  1.4574e-43,  6.4460e-44,\n",
       "         1.4153e-43,  1.5274e-43,  1.5695e-43,  1.6255e-43,  1.6956e-43])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.,  1.],\n",
      "        [ 1.,  1.]])\n",
      "tensor([[ 1.,  1.],\n",
      "        [ 1.,  1.]])\n",
      "<PowBackward1 object at 0x7f028d3eebe0>\n",
      "tensor([[ 3.,  3.],\n",
      "        [ 3.,  3.]]) tensor(3.)\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(2,2, requires_grad=True)\n",
    "print(x)\n",
    "y = x**x\n",
    "print(y)\n",
    "print(y.grad_fn)\n",
    "z = y * y * 3\n",
    "out = z.mean()\n",
    "\n",
    "print(z, out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### .requires_grad_( ... ) changes an existing Tensor’s requires_grad flag in-place. The input flag defaults to True if not given."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n",
      "<SumBackward0 object at 0x7f028d3eecc0>\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(2, 2)\n",
    "a = ((a * 3) / (a - 1))\n",
    "print(a.requires_grad)\n",
    "a.requires_grad_(True)\n",
    "print(a.requires_grad)\n",
    "b = (a * a).sum()\n",
    "print(b.grad_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradients\n",
    "#### Let’s backprop now Because out contains a single scalar, out.backward() is equivalent to out.backward(torch.tensor(1))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.5000,  1.5000],\n",
      "        [ 1.5000,  1.5000]])\n"
     ]
    }
   ],
   "source": [
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### You can also stops autograd from tracking history on Tensors with requires_grad=True by wrapping the code block in with torch.no_grad():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(x.requires_grad)\n",
    "print((x ** 2).requires_grad)\n",
    "\n",
    "with torch.no_grad():\n",
    "    print((x ** 2).requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Networks\n",
    "#### Neural networks can be constructed using the torch.nn package.\n",
    "\n",
    "> #### A typical training procedure for a neural network is as follows:\n",
    "> * Define the neural network that has some learnable parameters (or weights)\n",
    "> * Iterate over a dataset of inputs\n",
    "> * Process input through the network\n",
    "> * Compute the loss (how far is the output from being correct)\n",
    "> * Propagate gradients back into the network’s parameters\n",
    "> * Update the weights of the network, typically using a simple update rule: weight = weight - learning_rate * gradient\n",
    "\n",
    "## Define the network\n",
    "### Let’s define this network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn \n",
    "import torch.nn.functional as F \n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # 1 input image channel, 6 output channels\n",
    "        # 5X5 square convolution kernel\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        \n",
    "        # an affine operation : y = Wx +b \n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "                \n",
    "        # Max pool over 2X2 window \n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2,2))\n",
    "        \n",
    "        # can specify single number if size is square \n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), (2))\n",
    "        \n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "    def num_flat_features(self, x):\n",
    "        # All dimension except batch dimension\n",
    "        size = x.size()[1:] \n",
    "        num_features = 1 \n",
    "        for s in size:\n",
    "            num_features *=s\n",
    "        return num_features\n",
    "    \n",
    "    \n",
    "       \n",
    "net = Net()\n",
    "print(net)\n",
    "            \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
